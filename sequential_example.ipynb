{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HAAIL/PRADO-GoEmotions-Notebook/blob/main/sequential_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcNoWgG7hvIs"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/models/blob/master/research/seq_flow_lite/demo/colab/emotion_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/models/blob/master/research/seq_flow_lite/demo/colab/emotion_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aGnloeD1Mfo"
      },
      "source": [
        "### Install Tensorflow 2.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqP5qpAR1W4f"
      },
      "source": [
        "The seq_flow_lite library has been written with the assumption that tensorflow 2.10.0 will be used.  It may be necessary to restart the runtime after installing the correct version of Tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzuq_GVn1nXO"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXaKS_JBbyX1"
      },
      "source": [
        "Update CuDNN.  The version installed on the Colab machines does not play well with Tensorflow 2.10.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErZoDw_9bwSG"
      },
      "outputs": [],
      "source": [
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_mi4NZeeB1l"
      },
      "source": [
        "### Install the TensorFlow Datasets pip package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc4y4n80eL_b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "n0A6DScry3gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvsn_s3S0SAt"
      },
      "source": [
        "Load the data from TFDS:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLDbHTIvvX11"
      },
      "source": [
        "### Train and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "AELkd0n1dhLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unYlUYXq119f"
      },
      "outputs": [],
      "source": [
        "print(\"Data loading...\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string as strinG\n",
        "\n",
        "raw_data = pd.concat(map(pd.read_csv, ['goemotions_1.csv', 'goemotions_2.csv','goemotions_3.csv'])).to_numpy()\n",
        "keys =  [\n",
        "    'admiration',\n",
        "    'amusement',\n",
        "    'anger',\n",
        "    'annoyance',\n",
        "    'approval',\n",
        "    'caring',\n",
        "    'confusion',\n",
        "    'curiosity',\n",
        "    'desire',\n",
        "    'disappointment',\n",
        "    'disapproval',\n",
        "    'disgust',\n",
        "    'embarrassment',\n",
        "    'excitement',\n",
        "    'fear',\n",
        "    'gratitude',\n",
        "    'grief',\n",
        "    'joy',\n",
        "    'love',\n",
        "    'nervousness',\n",
        "    'optimism',\n",
        "    'pride',\n",
        "    'realization',\n",
        "    'relief',\n",
        "    'remorse',\n",
        "    'sadness',\n",
        "    'surprise',\n",
        "    'neutral'\n",
        "\n",
        "]\n",
        "print(raw_data[0])\n",
        "data = np.delete(raw_data[0:], [1, 2, 3, 4, 5, 6, 7, 8], 1)\n",
        "\n",
        "\n",
        "print(data[0])\n",
        "\n",
        "def preprocess(string):\n",
        "    # Strip URLs\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    string = url_pattern.sub(r'', string) \n",
        "\n",
        "    string = re.sub(\"\\S*@\\S*\\s?\", \"\", string)     # Strip Emails\n",
        "\n",
        "    string = re.sub(\"\\s+\", \" \", string)           # Strip newlines\n",
        "    \n",
        "    string = string.translate(str.maketrans('', '', strinG.punctuation)) # Strip Punctuation\n",
        "    \n",
        "    string = string.lower()\n",
        "    \n",
        "    return string\n",
        "\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(len(data)):\n",
        "    if(data[i][-1] != 1): # don't include \"neutral\" to avoid overfitting\n",
        "        X.append(preprocess(data[i][0]))\n",
        "        y.append(data[i][1:])\n",
        "\n",
        "X = np.array(X).astype(str)\n",
        "y = np.array(y).astype(float)\n",
        "\n",
        "text_dataset = tf.data.Dataset.from_tensor_slices(X) # for adapting\n",
        "        \n",
        "\n",
        "print(\"Data loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape\n",
        "X.shape\n",
        "print(\"y\")\n",
        "y.shape\n",
        "print(y[0])\n",
        "\n",
        "\n",
        "#len(keys)"
      ],
      "metadata": {
        "id": "ZsRwjOS2hwsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "x_train, x_test, Y_train, Y_test = train_test_split(list(text_dataset), y, train_size=0.8)\n",
        "\n",
        "X_train = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "y_test = tf.data.Dataset.from_tensor_slices(Y_test)\n",
        "y_train = tf.data.Dataset.from_tensor_slices(Y_train)\n",
        "X_test = tf.data.Dataset.from_tensor_slices(x_test)\n",
        "whole1 = tf.data.Dataset.from_tensor_slices((x_train, Y_train))\n",
        "whole2 = tf.data.Dataset.from_tensor_slices((x_test, Y_test))\n"
      ],
      "metadata": {
        "id": "rEDbR_zUdkzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkQMnTcLyFeR"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "print(\"Data loaded.\")\n",
        "import keras\n",
        "\n",
        "# Create Model\n",
        "\n",
        "max_words = 20000  # number of words to tokenize\n",
        "max_len = 300  # We allow up to 300 words per string. The largest in our dataset (after preprocessing) is 703 words\n",
        "\n",
        "tokenizer = keras.layers.TextVectorization(  # Vectorize Layer tokenizes words\n",
        "    max_tokens=max_words,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=max_len)\n",
        "\n",
        "print(\"token\")\n",
        "\n",
        "tokenizer.adapt(X_train.batch(64))  # adapt to the dataset of words\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))  # Takes a single string as an input\n",
        "model.add(tokenizer);  # The tokenizer. String -> Vector\n",
        "model.add(keras.layers.Embedding(max_words, 300))\n",
        "model.add(keras.layers.Conv1D(260, 8, activation=\"relu\"))  # Hidden sliding window. Dropout to reduce overfitting\n",
        "model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(100, activation=\"tanh\"))  # Hidden Layer\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.Dense(len(keys), activation=\"softmax\"))  # Output Layer\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "epochs = 4\n",
        "batch_size = 128\n",
        "# Fit the model weights.\n",
        "\n",
        "model.fit(whole1,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(whole2))\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vtUQZg7nBXn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def guessEmotion(string): # Finds the top 3 predictions\n",
        "    prediction = model.predict([preprocess(string)]).flatten()\n",
        "    for i in range(6):\n",
        "        best = np.argmax(prediction)\n",
        "        bestPercent = np.max(prediction)\n",
        "        print(\"Emotion \", i+1, \": \", keys[best], \" (\", bestPercent*100, \"%)\")\n",
        "        prediction[best] = -100 # Look for next-best prediction on the next loop pass"
      ],
      "metadata": {
        "id": "42t-UvDJd-F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guessEmotion(\"I love my puppy so much. She is adorable and goofy. I hope I have more pets with her personaility in the future. \")"
      ],
      "metadata": {
        "id": "OsUGYlJ3eT5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   try the XGBoost\n",
        "*   maybe change the labels\n",
        "*   stratify the sample \n",
        "*   get metrics to work \n",
        "*   simplify the network (keep dropout) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_0GefonGmlbS"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}